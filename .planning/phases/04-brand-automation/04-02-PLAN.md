---
phase: 04-brand-automation
plan: 02
type: execute
wave: 1
depends_on: ["04-01"]
files_modified:
  - scripts/scrape-digg-news.js
  - .github/workflows/sync-content.yml
  - package.json
autonomous: true
requirements: [DOC-02, CI-CD-01]

must_haves:
  truths:
    - "News scraper script extracts titles, dates, and links from Digg.se"
    - "Scraped items are converted into Docusaurus blog posts (.md)"
    - "Sync workflow triggers automatically on Repository Dispatch"
  artifacts:
    - path: "scripts/scrape-digg-news.js"
      provides: "Automated news ingestion logic"
    - path: ".github/workflows/sync-content.yml"
      provides: "Support for automated triggers from sandbox repo"
      contains: "repository_dispatch"
---

<objective>
Automate news ingestion from Digg.se and implement cross-repository triggers for real-time content updates.

Purpose: Eliminates manual triggers for content sync and ensures the "Nyheter" section is always populated with relevant external news.
Output: An automated news scraper and a fully responsive CI/CD pipeline.
</objective>

<execution_context>
@C:/Users/jcols/.gemini/get-shit-done/workflows/execute-plan.md
@C:/Users/jcols/.gemini/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-brand-automation/04-RESEARCH.md
@.planning/phases/04-brand-automation/04-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Install Scraper Dependencies</name>
  <files>package.json</files>
  <action>
    Install `axios` and `cheerio` to support the web scraping script.
    Command: `npm install axios cheerio`
  </action>
  <verify>`npm list axios cheerio` shows the installed versions.</verify>
  <done>Scraper tools are available in the project.</done>
</task>

<task type="auto">
  <name>Task 2: Implement Digg News Scraper</name>
  <files>scripts/scrape-digg-news.js</files>
  <action>
    1. Create the `scripts/` directory.
    2. Create `scripts/scrape-digg-news.js` using the logic from research:
       - Fetch `https://www.digg.se/om-oss/nyheter/digital-identitet/`.
       - Extract date, title, and link from each news item.
       - Generate a Markdown file in `blog/` for each item (format: `YYYY-MM-DD-title.md`).
       - Use frontmatter for `title`, `date`, and `link`.
  </action>
  <verify>Run `node scripts/scrape-digg-news.js` and check if new files appear in `blog/`.</verify>
  <done>News scraper is functional and generates blog posts.</done>
</task>

<task type="auto">
  <name>Task 3: Update Sync Workflow for Automation</name>
  <files>.github/workflows/sync-content.yml</files>
  <action>
    - Add `repository_dispatch: { types: [sync_content] }` to the `on` triggers in `.github/workflows/sync-content.yml`.
    - Integrate the news scraper into the workflow: Add a step to run `node scripts/scrape-digg-news.js` before the "Commit and Push" step.
    - (Optional) Clean up existing tutorial blog posts during the sync process.
  </action>
  <verify>Check `.github/workflows/sync-content.yml` for the updated trigger and scraper step.</verify>
  <done>Sync workflow is automated and includes external news ingestion.</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>Automated news scraper and cross-repo trigger support.</what-built>
  <how-to-verify>
    1. Verify that `scripts/scrape-digg-news.js` correctly generates blog files locally.
    2. Check the updated `sync-content.yml` on GitHub.
    3. **Action Required**: Add a new workflow in your *private sandbox repo* that sends a Repository Dispatch to `SIB_pages` on push. (I will provide the YAML for this).
  </how-to-verify>
  <resume-signal>Type "approved" or describe issues.</resume-signal>
</task>

</tasks>

<verification>
Run the news scraper locally and confirm that the generated blog posts are valid Docusaurus files. Verify that the sync workflow handles the new scraper step without errors.
</verification>

<success_criteria>
1. News from Digg.se is automatically converted into Docusaurus blog posts.
2. The `sync-content` workflow can be triggered remotely from the sandbox repo.
3. The blog section is automatically populated during the build process.
</success_criteria>

<output>
After completion, create `.planning/phases/04-brand-automation/04-02-SUMMARY.md`
</output>
